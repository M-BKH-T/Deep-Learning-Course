{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dc048c7-746e-470e-95aa-0ae6ca838a76",
   "metadata": {},
   "source": [
    "- # <font color='Pink' >Hi there</font>,<font color='Cyan'>I'm</font> <font color='red'>___M-BKH-T___ </font>ðŸ‘‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda1cf97-59a9-4499-bf55-c6a6428c55ff",
   "metadata": {},
   "source": [
    "This is Function API part 2\n",
    "\n",
    "In Previous part we created a very simple form of Function API \n",
    "But now we will build `WIDE` & `DEEP` Model with it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "193a940e-528c-4b5a-848b-ed3af37f2af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import what we need \n",
    "from tensorflow import keras \n",
    "import numpy as np \n",
    "from sklearn import preprocessing\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c259f6-1b63-4458-99fb-9785d20b3b53",
   "metadata": {},
   "source": [
    "Before creat model we need a model map \n",
    "\n",
    "<img src='https://github.com/M-BKH-T/Deep-Learning-Course/blob/main/Book1/Lesson3_Function%20API/image/wide_and_deep.png?raw=true'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18646d93-af64-4fcd-a26e-5c56f23aca40",
   "metadata": {},
   "source": [
    "lets buidl this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6549de3d-932b-4b7a-adb5-42b78ff38f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "house = datasets.fetch_california_housing() # call dataset function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bebfe6d6-43db-4b89-bf41-e7cbd6b45ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    " # first we need split input data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba22c987-b3a2-4c94-9383-aa60d649ff51",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train0, X_test, y_train0, y_test = train_test_split(\n",
    "                 house[\"data\"],\n",
    "                 house[\"target\"]) #first we need creat x & y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "642e1d49-918c-450e-a6f7-ec63118be905",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_validation, y_train1, y_validation = train_test_split(X_train0,\n",
    "                                                                  y_train0) # we can creat validation data or let the model create it by itself (validation split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c80a3821-61ce-456a-8c6a-0893f08b3f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train_s = sc.fit_transform(X_train1)\n",
    "X_validation_s = sc.transform(X_validation)\n",
    "X_test_s = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0fafbd-f98f-42fe-a92b-d2017cbf131d",
   "metadata": {},
   "source": [
    "#### this is the important part , we have to splite xtrain and validation in the two part v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6a6c8ec-da73-4779-b317-6ff09020fe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_s_1, X_train_s_2 = X_train_s[:, :6], X_train_s[:, -4:] # its easy dont confuse just specify how many data you want for each input \n",
    "X_validation_s_1, X_validation_s_2 = X_validation_s[:, :6], X_validation_s[:, -4:] # and repeat it for validations \n",
    "X_test_s_1, X_test_s_2 = X_test_s[:, :6], X_test_s[:, -4:] # and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d76dfa-be16-4db2-a152-ebf8ae2feea2",
   "metadata": {},
   "source": [
    "creat Model is same as part one just in this model we have a new layer , __`Concatenate`__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7df65604-0bfe-4c0b-9078-bcedb2f01619",
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_A = keras.layers.Input(shape=X_train_s_1.shape[1:])\n",
    "Input_B = keras.layers.Input(shape=X_train_s_2.shape[1:])\n",
    "hidden_layer1 = keras.layers.Dense(100 , activation=\"relu\" )(Input_B)\n",
    "hidden_layer2 = keras.layers.Dense(75 , activation=\"relu\" )(hidden_layer1)\n",
    "concat = keras.layers.Concatenate()([Input_A , hidden_layer2]) # this layer just can concate two layers not anything else\n",
    "output = keras.layers.Dense(1)(concat) # NOT forgot conect last layer\n",
    "model = keras.Model(inputs=[Input_A , Input_B] , outputs=[output]) # model is ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80f09545-72ab-439f-8d16-f72663fdec5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mean_squared_error\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[\"mean_absolute_error\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f18ffe-0e26-4090-95d1-1b517948a014",
   "metadata": {},
   "source": [
    "just in model.fit we  have to specify two ___xtrain___ and two ___x_val___ (Becouse we have two `inputs` in model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "905e1d55-188e-4d91-bd66-d47dcd84990e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "363/363 [==============================] - 3s 3ms/step - loss: 1.2680 - mean_absolute_error: 0.8054 - val_loss: 0.7602 - val_mean_absolute_error: 0.6185\n",
      "Epoch 2/3\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.7092 - mean_absolute_error: 0.5476 - val_loss: 0.5115 - val_mean_absolute_error: 0.5382\n",
      "Epoch 3/3\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4660 - mean_absolute_error: 0.4881 - val_loss: 0.4439 - val_mean_absolute_error: 0.4738\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a598758a60>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit((X_train_s_1, X_train_s_2), y_train1, validation_data=((X_validation_s_1 , X_validation_s_2) , (y_validation)) , epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0d3532-e5d0-4ab9-adeb-5bc85c1c37d9",
   "metadata": {},
   "source": [
    "As you can see model has no good accuracy and val_loss ,  Because its not easy to creat best model with function API \n",
    "and honestly we dont need it in many time , except for __big__ networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08601d49-06b7-4ed2-82a0-6f7249e840a5",
   "metadata": {},
   "source": [
    "<font color='grean'>Thank you for being with us</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
