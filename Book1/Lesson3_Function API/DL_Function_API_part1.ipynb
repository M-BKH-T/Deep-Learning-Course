{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f736512a-f432-450c-92e5-0e826d8e58e1",
   "metadata": {},
   "source": [
    "- # Hi there,I'm ___M-BKH-T___ ðŸ‘‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54007438-930a-4793-ae0f-4c3ad8e63c7c",
   "metadata": {},
   "source": [
    "Today i gonna show you how can we creat `Wide` and `Deep` model\n",
    "\n",
    "- At the beginning may ask ,  ___What___ is __Wide__ and __Deep__ Model?\n",
    "- And ___When___ do we use it? and ___Why___?\n",
    "---\n",
    "The answer to the first question is very easy\n",
    " Just look at this Model and you'll know \n",
    " \n",
    " <img src='https://github.com/M-BKH-T/Deep-Learning-Course/blob/main/Book1/Lesson3_Function%20API/image/wide_and_deep.png?raw=true'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69acc39c-7f65-44b4-b88a-0cc7a0ef92f9",
   "metadata": {},
   "source": [
    "__Deep__ Model is _exactly_ what we did in the previous session , in `Sequential`\n",
    "\n",
    "But ___WIDE___ and ___DEEP___ is diffrent , if we wanna creat WIDE & DEEp Model firts We shoud SPLITE Input Data (Input A and B) (we can use 100% of Input data ) and use one of them for deep part (for example Input B) and hold another for when we wanna Concat it  \n",
    "\n",
    "How can we do this?yes! with `Function API`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5faf8f5-46d2-4a56-a9a2-696ed5990852",
   "metadata": {},
   "source": [
    "First lets see how can we creat some easy Function API Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38427f3d-5062-4037-b994-c9b7784ca6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import what we need \n",
    "from tensorflow import keras \n",
    "import numpy as np \n",
    "from sklearn import preprocessing\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c438eb14-5b3c-4d0c-b69b-62e97ff9d377",
   "metadata": {},
   "outputs": [],
   "source": [
    "house = datasets.fetch_california_housing() # call dataset function\n",
    "pe = preprocessing.StandardScaler() # we gonna use this layer (for normalizing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf276ba7-bd09-4230-be83-121ba848d9af",
   "metadata": {},
   "source": [
    "more information about dataset --> [here](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c216bf1-b19b-4be1-b158-d46845294b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain , xtest , ytrain , ytest = train_test_split(house['data'] , house[\"target\"]) # creating x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4320d50f-117f-4aff-9e4b-db600052e7e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15480, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d67c5525-6d73-483f-b00a-71d60f29942c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15480,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d332519d-e807-4136-968d-916c2e447c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "395d7c8d-b148-4d7d-a7f3-a5f15fe5d7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_s = pe.fit_transform(xtrain) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00057ea1-edfd-4867-9d52-00e95ffe69c6",
   "metadata": {},
   "source": [
    "## Hits : Remember before do anything you need `Normalize` data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089b792b-656e-49b4-a742-10bc69e213f3",
   "metadata": {},
   "source": [
    "Now data is ready how can we creat Model?\n",
    "- First write layer name\n",
    "- Second call what layer you need  like this keras.layers.Dense\n",
    "- Thirs We need to specify which layer to connect to which one "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db3c7c0-614f-4874-8ee8-03c212cbc174",
   "metadata": {},
   "source": [
    "## layer name = keras.layers.---([],[])(layer name we wanna connect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85f81343-cfa4-4b82-ac8b-7b7e22697a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "Input = keras.layers.Input(shape=xtrain.shape[1:])\n",
    "hidden_layer1 = keras.layers.Dense(100 , activation=\"relu\" , kernel_initializer=\"he_normal\")(Input)\n",
    "hidden_layer2 = keras.layers.Dense(75 ,activation=\"relu\" , kernel_initializer=\"he_normal\" )(hidden_layer1)\n",
    "lk_relu = keras.layers.LeakyReLU(alpha=0.275)(hidden_layer2)\n",
    "output = keras.layers.Dense(1)(lk_relu)\n",
    "model = keras.Model(inputs=[Input] , outputs= [output])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb65f9da-5f60-4eac-ba64-587f232b2432",
   "metadata": {},
   "source": [
    "in the end \n",
    "- write model name\n",
    "- call keras.Model (not model)\n",
    "- Specify the input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c11080b1-8121-40db-ac66-849f79b86e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mean_squared_error\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"mean_absolute_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff51802d-40c2-412d-81d2-f9c3755842df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "484/484 [==============================] - 3s 2ms/step - loss: 1.3541 - mean_absolute_error: 0.6416\n",
      "Epoch 2/5\n",
      "484/484 [==============================] - 1s 2ms/step - loss: 10.3331 - mean_absolute_error: 0.7838\n",
      "Epoch 3/5\n",
      "484/484 [==============================] - 1s 2ms/step - loss: 0.8740 - mean_absolute_error: 0.5058\n",
      "Epoch 4/5\n",
      "484/484 [==============================] - 1s 2ms/step - loss: 0.4329 - mean_absolute_error: 0.4694\n",
      "Epoch 5/5\n",
      "484/484 [==============================] - 1s 2ms/step - loss: 0.4116 - mean_absolute_error: 0.4574\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2108404f850>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xtrain_s , ytrain , epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76533d7c-7c7d-40af-9fd0-e4e28a76409f",
   "metadata": {},
   "source": [
    "This is a simple  model with functioan API (its not wide and deep) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfa581d-e4be-4e53-aa6d-e6e3de5058c9",
   "metadata": {},
   "source": [
    "In next part together we will creat Wide & Deep Model "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
